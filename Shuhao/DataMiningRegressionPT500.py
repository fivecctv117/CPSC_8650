# -*- coding: utf-8 -*-
"""DataMining_Regression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1T5riL8lPmtPIAy5-bkZ2rJWZSUJ9WtFI
"""

#!pip install nibabel

import nibabel

from google.colab import drive
drive.mount('/content/drive',force_remount=True)
folder_path = '/content/drive/My Drive/DataMining/dataset/'

import pandas as pd
import os
import nibabel as nib
import numpy as np
# 读取Excel文件
labels_path = '/content/drive/MyDrive/DataMining/label/PTs_500_4k_blinded.xlsx'
labels_df = pd.read_excel(labels_path)


# 显示Excel文件的前几行，以确认内容
print(labels_df.head())

def convert_excel_id_to_filename_corrected(excel_id):
    """
    将Excel中的ID正确转换为图像文件名的格式。
    例如，将'smwp1_0001'转换为'smwp10001'。
    """
    parts = excel_id.split('_')  # 分割ID
    prefix = parts[0][:-1]  # 获取前缀，并移除末尾的数字
    number = parts[1]  # 获取数字部分
    if len(number) < 5:
        number = '1' + '0' * (4 - len(number)) + number  # 确保数字部分是5位的，以1开始
    new_id = prefix + number
    return new_id

# 应用转换逻辑到整个DataFrame上
labels_df['Converted_ID'] = labels_df['ID'].apply(convert_excel_id_to_filename_corrected)

# 显示转换后的结果，以确认转换是否正确
print(labels_df[['ID', 'Converted_ID']].head())


# 指定包含NIfTI文件的文件夹路径
nii_folder_path = '/content/drive/MyDrive/DataMining/dataset/'

# 初始化一个列表来存储（文件名，图像数据）元组
nii_images_info = []

# 遍历文件夹中的所有文件
for file_name in os.listdir(nii_folder_path):
    # 检查文件扩展名是否为.nii
    if file_name.endswith('.nii'):
        # 构建完整的文件路径
        file_path = os.path.join(nii_folder_path, file_name)

        # 使用nibabel加载NIfTI文件
        nii_image = nib.load(file_path)

        # 获取数据数组
        image_data = nii_image.get_fdata()

        # 将（文件名，数据数组）元组添加到列表中
        nii_images_info.append((file_name, image_data))

# 此时，nii_images_info 包含了文件夹中所有NIfTI文件的文件名和图像数据
# 例如，打印加载的图像及其文件名数量
print(f"Loaded {len(nii_images_info)} NIfTI images.")

# 如果需要进一步处理每个图像，你可以遍历nii_images_info列表
# 访问第一个图像的文件名和数据
first_image_file_name, first_image_data = nii_images_info[0]
print(f"First image file name: {first_image_file_name}, data shape: {first_image_data.shape}")

# Load data to python
import os
import numpy as np
from PIL import Image
import pandas as pd
from torchvision import transforms
import nibabel as nib
import matplotlib.pyplot as plt  # 导入matplotlib
import torch

# # 定义预处理转换
# transform = transforms.Compose([
#     transforms.Resize((224, 224)),  # 调整图像大小
#     transforms.ToTensor(),  # 将图像转换为浮点型tensor
#     transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),  # 归一化
# ])

from torchvision import transforms

#定义预处理变换并使用数据增强技术
transform = transforms.Compose([
    transforms.RandomHorizontalFlip(), # 随机水平翻转
    transforms.RandomRotation(15), # 随机旋转
    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1), # 随机颜色变换
    transforms.RandomResizedCrop(size=(224, 224), scale=(0.8, 1.0)), # 随机裁剪并调整大小
    transforms.ToTensor(), # 将图片转换为Tensor
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]), # 标准化
])




# 创建一个函数来调整切片的大小
def resize_slice(slice, target_height, target_width):
    img_pil = Image.fromarray(slice)
    img_resized = img_pil.resize((target_width, target_height), Image.ANTIALIAS)
    return np.array(img_resized)

#device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# 初始化图像和标签的列表
images = []  # 存储预处理后的图像数据
labels = []  # 存储匹配到的标签

for image_file_name, image_data in nii_images_info:
    # 移除图像文件名的扩展名和后缀，以便与转换后的Excel ID进行匹配
    base_name = os.path.splitext(image_file_name)[0]
    base_name = base_name[:-3]  # 假设所有文件名都以'_T1'结尾，移除这部分

    # 查找匹配的行
    matching_rows = labels_df[labels_df['Converted_ID'] == base_name]
    if not matching_rows.empty:
        label = matching_rows['PT500'].iloc[0]  # 假设我们关心的标签在'PT500'列

        # 选择中间切片。假设 image_data 是一个3D numpy数组
        middle_slice_z = image_data[:, :, image_data.shape[2] // 2]
        # 选择沿x轴的中间切片
        middle_slice_x = image_data[image_data.shape[0] // 2, :, :]
        # 选择沿y轴的中间切片
        middle_slice_y = image_data[:, image_data.shape[1] // 2, :]

        # 将numpy数组转换为0-255范围的uint8（根据你的数据可能需要调整）
        #middle_slice_normalized = ((middle_slice - middle_slice.min()) / (middle_slice.max() - middle_slice.min()) * 255).astype(np.uint8)
        middle_slice_z_normalized = ((middle_slice_z - middle_slice_z.min()) / (middle_slice_z.max() - middle_slice_z.min()) * 255).astype(np.uint8)
        middle_slice_x_normalized = ((middle_slice_x - middle_slice_x.min()) / (middle_slice_x.max() - middle_slice_x.min()) * 255).astype(np.uint8)
        middle_slice_y_normalized = ((middle_slice_y - middle_slice_y.min()) / (middle_slice_y.max() - middle_slice_y.min()) * 255).astype(np.uint8)

        # 获取三个切片的大小，并找出要调整到的目标大小
        target_height = min(middle_slice_x.shape[0], middle_slice_y.shape[0], middle_slice_z.shape[0])
        target_width = min(middle_slice_x.shape[1], middle_slice_y.shape[1], middle_slice_z.shape[1])

        # 调整每个切片的大小
        middle_slice_x_resized = resize_slice(middle_slice_x_normalized, target_height, target_width)
        middle_slice_y_resized = resize_slice(middle_slice_y_normalized, target_height, target_width)
        middle_slice_z_resized = resize_slice(middle_slice_z_normalized, target_height, target_width)

        # 沿新轴堆叠切片
        stacked_slices = np.stack([middle_slice_x_resized, middle_slice_y_resized, middle_slice_z_resized], axis=-1)
        #print(stacked_slices.shape)

        # 如果需要，可以在这里调整 stacked_slices 的大小
        # 例如，使用 PIL 调整图像大小
        img_pil = Image.fromarray(stacked_slices)
        target_size = (224, 224)  # 假定目标尺寸为 224x224
        img_resized = img_pil.resize(target_size, Image.ANTIALIAS)
        transformed_image = transform(img_resized)
        print('=============================')
        print(transformed_image.shape)
        print(transformed_image)
        print('=============================')


        # 添加到列表中，后续可以作为模型的输入
        images.append(transformed_image)
        labels.append(label)
        print(f"Image: {image_file_name}, Label: {label}")

# 转换列表为张量
# 对于图像，使用torch.stack()，因为每个图像已经是一个张量
# images_tensor = torch.stack(images).to(device)
# # 对于标签，直接使用torch.tensor()转换列表为张量
# labels_tensor = torch.tensor(labels, dtype=torch.long).to(device)

# # 将张量移动到GPU
# images_GPU = images_tensor.to(device)
# labels_GPU = labels_tensor.to(device)


# print("numbers of lables:",len(labels))
num_classes = len(set(labels))
#print(f"Number of classes: {num_classes}")


##Divide dataset
from sklearn.model_selection import train_test_split

# 首先将数据分割为训练+验证集和独立的测试集
train_val_images, test_images, train_val_labels, test_labels = train_test_split(
    images, labels, test_size=0.2, random_state=42)

# 然后从训练+验证集中进一步分割出训练集和验证集
train_images, val_images, train_labels, val_labels = train_test_split(
    train_val_images, train_val_labels, test_size=0.25, random_state=42)  # 注意: 这里的test_size是相对于train_val_images而言的

from torch.utils.data import Dataset, DataLoader
from transformers import ViTForImageClassification
import torch
from torch.optim import optimizer
import torch.optim as optim
from transformers import get_linear_schedule_with_warmup
from transformers import ViTForImageClassification

# 加载数据
class CustomDataset(Dataset):
    def __init__(self, images, labels):
        self.images = images
        self.labels = labels

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        image = self.images[idx]
        label = self.labels[idx]
        return image, label

# 创建Dataset实例
train_dataset = CustomDataset(train_images, train_labels)
val_dataset = CustomDataset(val_images, val_labels)
test_dataset = CustomDataset(test_images, test_labels)

num_classes_train = len(set(train_labels))
num_classes_val = len(set(val_labels))
num_classes_test = len(set(test_labels))

print("Number of classes in train:", num_classes_train)
print("Number of classes in val:", num_classes_val)
print("Number of classes in test:", num_classes_test)

# 设置DataLoader
train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)

#加载模型
# 首先，检查CUDA是否可用
#device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# 加载预先训练好的模型
model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224-in21k')
# model = AutoencoderKL.from_pretrained("microsoft/mri-autoencoder-v0.1")

model.classifier = torch.nn.Linear(model.config.hidden_size, 1)
# 将模型移动到指定的设备上（GPU或回退到CPU）
#model.to(device)

# 打印当前使用的设备，确认模型已被正确移动
#print(f"Using device: {device}")

#假设是多分类任务
# 替换分类头
#num_labels = 19  # 你的数据集的类别数
#model.classifier = torch.nn.Linear(model.config.hidden_size, num_labels)

#损失函数
criterion = torch.nn.MSELoss()
#optimizer = optim.Adam(model.parameters(), lr=0.001)
optimizer = optim.Adam(model.parameters(), lr=0.0015, weight_decay=1e-5)
#dynamic midify learning rate
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.1, verbose=True)

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard
# %tensorboard --logdir runs/

from torch.utils.tensorboard import SummaryWriter
from tqdm import tqdm
from sklearn.metrics import mean_squared_error, mean_absolute_error
from math import sqrt
from scipy.stats import pearsonr


# 设置TensorBoard的日志目录
writer = SummaryWriter('runs/lr00015/')
num_epochs = 15

num_classes = len(set(train_labels))
print("Number of classes in labels:", num_classes)

for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    #model.to(device)
    # 使用tqdm创建进度条
    train_bar = tqdm(enumerate(train_loader), total=len(train_loader))
    for i, (images, labels) in train_bar:
        # images = images.to(device)
        # labels = labels.to(device)
        # 清除梯度
        optimizer.zero_grad()

        # 前向传播，反向传播，优化
        outputs = model(images).logits
        # print(print("Logits shape:", outputs.shape))
        # print("Logits:", outputs.shape)
        # print("Labels:", labels)
        loss = criterion(outputs, labels.float())
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

        # 每n个批次更新进度条描述
        if i % 100 == 99:
            train_bar.set_description(f"Epoch {epoch+1}/{num_epochs} Loss: {running_loss/100:.4f}")
            writer.add_scalar('training loss', running_loss / 100, epoch * len(train_loader) + i)
            running_loss = 0.0
    scheduler.step(running_loss / len(train_loader))
    # 验证过程中记录验证LOSS和计算回归指标
    model.eval()
    val_loss = 0.0
    # 累计预测值和真实值，以计算回归指标
    all_predicted = []
    all_labels = []

    val_bar = tqdm(enumerate(val_loader), total=len(val_loader))
    with torch.no_grad():
        for i, (images, labels) in val_bar:
            outputs = model(images)
            loss = criterion(outputs.logits.squeeze(-1), labels.float())  # 确保logits与labels的维度一致
            val_loss += loss.item()
            all_predicted.extend(outputs.logits.squeeze(-1).tolist())  # 降低维度并转为列表
            all_labels.extend(labels.tolist())
            val_bar.set_description("Validating... ")

    val_loss /= len(val_loader)

    # 计算回归指标
    mse = mean_squared_error(all_labels, all_predicted)
    rmse = sqrt(mse)
    mae = mean_absolute_error(all_labels, all_predicted)
    pearson_corr, _ = pearsonr(all_predicted, all_labels)

    writer.add_scalar('validation loss', val_loss, epoch)
    writer.add_scalar('validation MSE', mse, epoch)
    writer.add_scalar('validation RMSE', rmse, epoch)
    writer.add_scalar('validation MAE', mae, epoch)
    writer.add_scalar('validation Pearson Correlation', pearson_corr, epoch)
    tqdm.write(f'Epoch {epoch+1}/{num_epochs} Validation Loss: {val_loss:.4f} MSE: {mse:.4f} RMSE: {rmse:.4f} MAE: {mae:.4f} Pearson Correlation: {pearson_corr:.4f}')

    # 保存模型
    #torch.save(model.state_dict(), f'model_{epoch+1}.pth')

from scipy.stats import pearsonr
#Test model in Test dataset
model.eval()  # 将模型设置为评估模式
test_loss = 0.0
all_predicted = []
all_labels = []

# 不计算梯度，以节省内存和计算资源
with torch.no_grad():
    for images, labels in test_loader:  # 假设test_loader是你的测试数据加载器
        # 如果使用GPU
        # images, labels = images.to(device), labels.to(device)

        outputs = model(images)
        loss = criterion(outputs.logits.squeeze(-1), labels.float())
        test_loss += loss.item()
        all_predicted.extend(outputs.logits.squeeze(-1).tolist())
        all_labels.extend(labels.tolist())

# 计算整个测试集上的平均损失
test_loss /= len(test_loader)

# 计算其他性能指标
mse = mean_squared_error(all_labels, all_predicted)
rmse = sqrt(mse)
mae = mean_absolute_error(all_labels, all_predicted)
pearson_corr, _ = pearsonr(all_predicted, all_labels)

# 打印性能指标
print(f'Test Loss: {test_loss:.4f}')
print(f'MSE: {mse:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}, Pearson Correlation: {pearson_corr:.4f}')